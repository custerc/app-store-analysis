{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guided Project: App Data Analysis\n",
    "\n",
    "The goal of this project is to analyze data from the app store and discover what types of free apps might be most profitable to develop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first cell, we define a new function called `explore_data()` that takes up to four arguments: the name of a dataset (which should be a list of lists), integers for the start and end that represent the size slice you want to look at (i.e. on which row you want to begin and end), and a Boolean called `rows_and_columns` which is `False` by default, but which will display the dataset's _total_ number of rows and columns if given the argument `True`.\n",
    "\n",
    "So, for example, if you wanted to see the first two (real) rows of the ios dataset as well as count rows and columns, you would enter the argument `ios_data, 1, 3, True` for this function.\n",
    "\n",
    "Note, also, that this assumes the dataset has no header row. If it does have one, you should enter the dataset as `dataset[1:]` or the function's count of rows will be off by one because it's counting the header row as a row of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') #adds empty line after each row\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, we import the data sets, open them, and convert them to lists of lists. Note that we need to specify `encoding=\"utf8\"` as an argument in `open()` in order to get these files to read properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_ios = open('C:/users/Charlie/datasets/AppleStore.csv', encoding=\"utf8\")\n",
    "opened_android = open('C:/users/Charlie/datasets/googleplaystore.csv', encoding=\"utf8\")\n",
    "\n",
    "read_ios = reader(opened_ios)\n",
    "read_android = reader(opened_android)\n",
    "\n",
    "ios_data = list(read_ios)\n",
    "android_data = list(read_android)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '281796108', 'Evernote - stay organized', '158578688', 'USD', '0', '161065', '26', '4', '3.5', '8.2.2', '4+', 'Productivity', '37', '5', '23', '1']\n",
      "\n",
      "\n",
      "Number of rows: 7197\n",
      "Number of columns: 17\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Number of rows: 10841\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(ios_data[1:], 1, 2, True)\n",
    "explore_data(android_data[1:], 1, 2, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That has given us a decent idea of how the data looks. Now, let's look at the header rows and assess which are likely to be the most useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['', 'id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']]\n",
      "[['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']]\n"
     ]
    }
   ],
   "source": [
    "print(ios_data[:1])\n",
    "print(android_data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `ios_data`, the most useful columns are probably `price` (index 5), `rating_count_tot` (index 6), `user_rating` (index 8), `content_rating` (index 11), and `prime_genre` (index 12).\n",
    "\n",
    "In `android_data` the corresponding columns are `price` (index 7), `reviews` (index 3), `rating` (index 2), `Content Rating` (index 8) and `genres` (index 9).\n",
    "\n",
    "In the Android dataset, `installs` might be useful as well, but it has no corresponding column in the iOS data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "Now we're going to clean the data. From the dataset's source on Kaggle, we know that the Android data has an error in row 10472, so we're going to delete that from the dataset using `del[index]`.\n",
    "\n",
    "So that we don't make a mistake, let's just print a few rows around the problem area to confirm we've got the right row. It's not clear whether the user's report of a mistake refers to the actual row 10472 or row 10472 of the dataset (which includes the header) so let's just double-check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Jazz Wi-Fi', 'COMMUNICATION', '3.4', '49', '4.0M', '10,000+', 'Free', '0', 'Everyone', 'Communication', 'February 10, 2017', '0.1', '2.3 and up'], ['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up'], ['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']]\n",
      "\n",
      "\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "print(android_data[10471:10474])\n",
    "print('\\n')\n",
    "print(android_data[10473])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that the issue is with `android_data[10473]`: the `Category` column was skipped in this row, and all the subsequent data points in this are thus not indexed correctly because they've been shifted one place earlier in the index. \n",
    "\n",
    "Let's go ahead and delete this row. Then, let's use `explore_data()` to check those rows, just to ensure everything looks correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jazz Wi-Fi', 'COMMUNICATION', '3.4', '49', '4.0M', '10,000+', 'Free', '0', 'Everyone', 'Communication', 'February 10, 2017', '0.1', '2.3 and up']\n",
      "\n",
      "\n",
      "['Xposed Wi-Fi-Pwd', 'PERSONALIZATION', '3.5', '1042', '404k', '100,000+', 'Free', '0', 'Everyone', 'Personalization', 'August 5, 2014', '3.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['osmino Wi-Fi: free WiFi', 'TOOLS', '4.2', '134203', '4.1M', '10,000,000+', 'Free', '0', 'Everyone', 'Tools', 'August 7, 2018', '6.06.14', '4.4 and up']\n",
      "\n",
      "\n",
      "['Sat-Fi Voice', 'COMMUNICATION', '3.4', '37', '14M', '1,000+', 'Free', '0', 'Everyone', 'Communication', 'November 21, 2014', '2.2.1.5', '2.2 and up']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "del android_data[10473]\n",
    "explore_data(android_data, 10471, 10475)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's clean the datasets of duplicate apps.\n",
    "\n",
    "We're creating new empty lists for duplicate and unique apps in each dataset. Then, in separate `for` loops, we're looping through each row of the `ios_data` and `android_data` datasets to check whether the name already exists in the unique dataset list. If it does, it's added to the duplicate list. If it doesn't, it's added to the unique list.\n",
    "\n",
    "Then we quickly explore the duplicate datasets to see how much we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Android duplicates:\n",
      "Box\n",
      "\n",
      "\n",
      "Google My Business\n",
      "\n",
      "\n",
      "ZOOM Cloud Meetings\n",
      "\n",
      "\n",
      "join.me - Simple Meetings\n",
      "\n",
      "\n",
      "Box\n",
      "\n",
      "\n",
      "Zenefits\n",
      "\n",
      "\n",
      "Google Ads\n",
      "\n",
      "\n",
      "Google My Business\n",
      "\n",
      "\n",
      "Slack\n",
      "\n",
      "\n",
      "Number of rows: 1181\n",
      "Number of columns: 28\n",
      "iOS duplicates:\n",
      "Mannequin Challenge\n",
      "\n",
      "\n",
      "Number of rows: 2\n",
      "Number of columns: 17\n"
     ]
    }
   ],
   "source": [
    "duplicate_android = []\n",
    "unique_android = []\n",
    "duplicate_ios = []\n",
    "unique_ios = []\n",
    "\n",
    "for app in android_data:\n",
    "    name = app[0]\n",
    "    if name in unique_android:\n",
    "        duplicate_android.append(name)\n",
    "    else:\n",
    "        unique_android.append(name)\n",
    "        \n",
    "for app in ios_data:\n",
    "    name = app[2]\n",
    "    if name in unique_ios:\n",
    "        duplicate_ios.append(name)\n",
    "    else:\n",
    "        unique_ios.append(name)\n",
    "\n",
    "print('Android duplicates:')        \n",
    "explore_data(duplicate_android, 1, 10, True)\n",
    "print('iOS duplicates:')\n",
    "explore_data(duplicate_ios, 1, 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the iOS dataset included just one duplicate entry, but the Android data included a lot (1,181!). We've now quarantined those duplicates, and created dupe-free datasets called `unique_ios` and `unique_android`. However, these new datasets aren't perfect, because in the code above, we removed the duplicate datasets randomly, storing whichever entry appeared first in the `'unique` dataset and removing the others. This probably doesn't matter for the iOS list, but for the Android list with so many duplicates, it might.\n",
    "\n",
    "Instead of doing this, we probably want to store whichever entry has the highest number of user ratings, since that's likely to be the oldest and/or primary entry, and may give us the best measure of the app's popularity. Given that the Android dataset also includes number of installs (index 5), this might be a good measure as well, but this data is stored in an annoying string format (10M, 40K) so let's just stick with Ratings.\n",
    "\n",
    "So let's do that cleaning again, but this time store the duplicate with the highest number of reviews in the `unique` dataset. First, let's get a measure of the different review counts we have for the Instagram app so that so that we can test to see if we've really gotten the highest one later when we make our dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66577313\n",
      "66577446\n",
      "66577313\n",
      "66509917\n"
     ]
    }
   ],
   "source": [
    "for app in android_data[1:]:\n",
    "    name = app[0]\n",
    "    if name == 'Instagram':\n",
    "        print(app[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know that the HIGHEST review count for Instagram is **66,577,446**. So once we've created our dictionary of the highest number of reviews per app, that's the count we should get.\n",
    "\n",
    "Let's create a dictionary called `reviews_max` and then look through `android_data`. If an app name appears in the data and its reviews count is less than what's in `reviews_max`, we want to replace the current definition for that app name in with the higher reviews count. If it isn't in the dictionary yet at all, then we want to add the app name and its reviews count to the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66577446.0\n",
      "Expected length: 9659\n",
      "Actual length: 9659\n"
     ]
    }
   ],
   "source": [
    "reviews_max = {} \n",
    "\n",
    "for app in android_data[1:]:\n",
    "    name = app[0]\n",
    "    reviews = float(app[3])\n",
    "    if name in reviews_max and reviews_max[name] < reviews:\n",
    "        reviews_max[name] = reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = reviews\n",
    "        \n",
    "print(reviews_max['Instagram'])\n",
    "\n",
    "print('Expected length:', len(android_data[1:]) - 1181)\n",
    "print('Actual length:', len(reviews_max))\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, it worked! Now we need to get this back into a list.\n",
    "\n",
    "First, we'll creat a couple new empty lists. Then we'll loop through the original data set and pull app names and review numbers. For each app, we'll check if the listed review number is the same as what's in our `max_reviews` dictionary. If it is, and if the app's name hasn't been added yet, we'll add that app to the `android_clean` list. Then we'll add it to the `already_added` list just to have a record of what's been added. \n",
    "\n",
    "This should leave us with a list of each app that includes no duplicates and that has chosen the duplicate entry with the highest review count for each app. We'll use our `explore_data()` function to take a quick look at the new `android clean` list after building it to make sure everything looks right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite ‚Äì FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "Number of rows: 9659\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "android_clean = []\n",
    "already_added = []\n",
    "\n",
    "for app in android_data[1:]:\n",
    "    name = app[0]\n",
    "    n_reviews = float(app[3])\n",
    "    \n",
    "    if (reviews_max[name] == n_reviews) and (name not in already_added):\n",
    "        android_clean.append(app)\n",
    "        already_added.append(name)\n",
    "    \n",
    "explore_data(android_clean, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to try and remove apps that contain non-English names, since they're probably not aimed at an English speaking audience. We may not be able to easily detect other languages that use the English alphabet, but we can identify apps that use-non English alphabets in their names.\n",
    "\n",
    "First, let's write a function and test it to see if it correctly identifies non-English app names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def english_finder(string):\n",
    "    for character in string:\n",
    "        value = ord(character)\n",
    "        if value > 127:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(english_finder(\"Instagram\"))\n",
    "print(english_finder(\"Áà±Â•áËâ∫PPS\"))\n",
    "print(english_finder(\"Instachat üòú\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this works, but it would also eliminate non-English names that use emoji. Let's rewrite it to only return false if there are more than 3 such characters in the app name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def english_finder(string):\n",
    "    n = 0\n",
    "    for character in string:\n",
    "        value = ord(character)\n",
    "        if value > 127:\n",
    "            n += 1\n",
    "        if n >= 3:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print(english_finder(\"Instagram\"))\n",
    "print(english_finder(\"Áà±Â•áËâ∫PPS\"))\n",
    "print(english_finder(\"Instachat üòú\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lovely! Let's now use that function to filter out the non-English apps in our `android_clean` and `ios_data` datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite ‚Äì FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "Number of rows: 9597\n",
      "Number of columns: 13\n",
      "['', 'id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['1', '281656475', 'PAC-MAN Premium', '100788224', 'USD', '3.99', '21292', '26', '4', '4.5', '6.3.5', '4+', 'Games', '38', '5', '10', '1']\n",
      "\n",
      "\n",
      "['2', '281796108', 'Evernote - stay organized', '158578688', 'USD', '0', '161065', '26', '4', '3.5', '8.2.2', '4+', 'Productivity', '37', '5', '23', '1']\n",
      "\n",
      "\n",
      "Number of rows: 6156\n",
      "Number of columns: 17\n",
      "['Truy·ªán Vui T√Ω Qu·∫≠y', 'Flame - ÿØÿ±ÿ® ÿπŸÇŸÑŸÉ ŸäŸàŸÖŸäÿß', 'At home - rental ¬∑ real estate ¬∑ room finding application such as apartment ¬∑ apartment', '‰πêÂ±ãÁΩë: Buying a house, selling a house, renting a house', '·Äû·Ä≠·ÄÑ·Ä∫·Äπ Astrology - Min Thein Kha BayDin', '–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏', '‰πóÊèõNAVITIME\\u3000Timetable & Route Search in Japan Tokyo', '‚ñ∫ MultiCraft ‚Äï Free Miner! üëç', 'ÿµŸàÿ± ÿ≠ÿ±ŸÅ H', 'L.POINT - ÏóòÌè¨Ïù∏Ìä∏ [ Ìè¨Ïù∏Ìä∏, Î©§Î≤ÑÏã≠, Ï†ÅÎ¶Ω, ÏÇ¨Ïö©, Î™®Î∞îÏùº Ïπ¥Îìú, Ïø†Ìè∞, Î°ØÎç∞]']\n"
     ]
    }
   ],
   "source": [
    "android_eng = []\n",
    "ios_eng = []\n",
    "non_english = [] # just for checking to see if it's working correctly\n",
    "\n",
    "for app in android_clean:\n",
    "    name = app[0]\n",
    "    is_english = english_finder(name)\n",
    "    if is_english == True:\n",
    "        android_eng.append(app)\n",
    "    elif is_english == False:\n",
    "        non_english.append(name)\n",
    "        \n",
    "for app in ios_data:\n",
    "    name = app[2]\n",
    "    is_english = english_finder(name)\n",
    "    if is_english == True:\n",
    "        ios_eng.append(app)\n",
    "    elif is_english == False:\n",
    "        non_english.append(name)\n",
    "        \n",
    "        \n",
    "explore_data(android_eng, 0, 3, True)\n",
    "explore_data(ios_eng, 0, 3, True)  \n",
    "print(non_english[0:10])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since in this exercise we're working for an app company that only makes free apps, we now want to reduce these datasets one more time to create lists with only the free apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite ‚Äì FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "Number of rows: 8847\n",
      "Number of columns: 13\n",
      "['2', '281796108', 'Evernote - stay organized', '158578688', 'USD', '0', '161065', '26', '4', '3.5', '8.2.2', '4+', 'Productivity', '37', '5', '23', '1']\n",
      "\n",
      "\n",
      "['3', '281940292', 'WeatherBug - Local Weather, Radar, Maps, Alerts', '100524032', 'USD', '0', '188583', '2822', '3.5', '4.5', '5.0.0', '4+', 'Weather', '37', '5', '3', '1']\n",
      "\n",
      "\n",
      "['4', '282614216', 'eBay: Best App to Buy, Sell, Save! Online Shopping', '128512000', 'USD', '0', '262241', '649', '4', '4.5', '5.10.0', '12+', 'Shopping', '37', '5', '9', '1']\n",
      "\n",
      "\n",
      "Number of rows: 3203\n",
      "Number of columns: 17\n",
      "['TurboScan: scan documents and receipts in PDF', 'BUSINESS', '4.7', '11442', '6.8M', '100,000+', 'Paid', '$4.99', 'Everyone', 'Business', 'March 25, 2018', '1.5.2', '4.0 and up']\n",
      "\n",
      "\n",
      "['Tiny Scanner Pro: PDF Doc Scan', 'BUSINESS', '4.8', '10295', '39M', '100,000+', 'Paid', '$4.99', 'Everyone', 'Business', 'April 11, 2017', '3.4.6', '3.0 and up']\n",
      "\n",
      "\n",
      "['Puffin Browser Pro', 'COMMUNICATION', '4.0', '18247', 'Varies with device', '100,000+', 'Paid', '$3.99', 'Everyone', 'Communication', 'July 5, 2018', '7.5.3.20547', '4.1 and up']\n",
      "\n",
      "\n",
      "Number of rows: 3702\n",
      "Number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "android_free = []\n",
    "ios_free = []\n",
    "not_free = [] # just to test it's working correctly\n",
    "\n",
    "for app in android_eng:\n",
    "    price = app[6]\n",
    "    if price == 'Free' or price == 'free' or price == 0:\n",
    "        android_free.append(app)\n",
    "    else:\n",
    "        not_free.append(app)\n",
    "        \n",
    "        # I did the above loop the hard way, using index 7 (numeric price) would have been simpler...\n",
    "        \n",
    "for app in ios_eng[1:]:\n",
    "    price = float(app[5])\n",
    "    if price == 0:\n",
    "        ios_free.append(app)\n",
    "    else:\n",
    "        not_free.append(app)\n",
    "        \n",
    "explore_data(android_free, 0, 3, True)\n",
    "explore_data(ios_free, 0, 3, True)\n",
    "explore_data(not_free, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Now that we've got some relatively clean lists of data in `android_free` and `ios_free`, it's time to start actually analyzing stuff. The first thing we'll probably want to do is look at the **genres** (index 9 for android and 12 for ios). Category (index 1) might also be useful for Android.\n",
    "\n",
    "Annoyingly, because there are a lot of genres, we'll want to create sorted frequency tables. There is a `sorted()` function in Python, but it doesn't work well with dictionaries, so we'll need to create dictionaries with the genre as the key, the number of apps in that genre as the dictionary value, and then turn that dictionany into a list of tuples. We'll use the provided `display_table()` function to do this and to display the sorted tables, but first we need to create a `freq_table` function that can take our list of lists and turn it into a frequency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Productivity': 56, 'Weather': 28, 'Shopping': 83, 'Reference': 17, 'Finance': 35, 'Music': 66, 'Utilities': 79, 'Travel': 40, 'Social Networking': 106, 'Sports': 69, 'Health & Fitness': 65, 'Games': 1866, 'Food & Drink': 26, 'News': 43, 'Book': 12, 'Photo & Video': 160, 'Entertainment': 251, 'Business': 17, 'Lifestyle': 50, 'Education': 118, 'Navigation': 6, 'Medical': 6, 'Catalogs': 4}\n"
     ]
    }
   ],
   "source": [
    "def freq_table(list, index):\n",
    "    frequency = {}\n",
    "    for app in list:\n",
    "        genre = app[index]\n",
    "        if genre in frequency:\n",
    "            frequency[genre] += 1\n",
    "        else:\n",
    "            frequency[genre] = 1\n",
    "    return frequency\n",
    "\n",
    "print(freq_table(ios_free, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to be working, so let's try to combine it with the pre-written `display_table()` function provided by Dataquest to see if we can get a properly sorted table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iOS table:\n",
      "Games : 1866\n",
      "Entertainment : 251\n",
      "Photo & Video : 160\n",
      "Education : 118\n",
      "Social Networking : 106\n",
      "Shopping : 83\n",
      "Utilities : 79\n",
      "Sports : 69\n",
      "Music : 66\n",
      "Health & Fitness : 65\n",
      "Productivity : 56\n",
      "Lifestyle : 50\n",
      "News : 43\n",
      "Travel : 40\n",
      "Finance : 35\n",
      "Weather : 28\n",
      "Food & Drink : 26\n",
      "Reference : 17\n",
      "Business : 17\n",
      "Book : 12\n",
      "Navigation : 6\n",
      "Medical : 6\n",
      "Catalogs : 4\n",
      "None\n",
      "\n",
      "\n",
      "Android table Category:\n",
      "FAMILY : 1675\n",
      "GAME : 858\n",
      "TOOLS : 748\n",
      "BUSINESS : 407\n",
      "PRODUCTIVITY : 345\n",
      "LIFESTYLE : 344\n",
      "FINANCE : 328\n",
      "MEDICAL : 313\n",
      "SPORTS : 300\n",
      "PERSONALIZATION : 294\n",
      "COMMUNICATION : 286\n",
      "HEALTH_AND_FITNESS : 273\n",
      "PHOTOGRAPHY : 261\n",
      "NEWS_AND_MAGAZINES : 248\n",
      "SOCIAL : 236\n",
      "TRAVEL_AND_LOCAL : 207\n",
      "SHOPPING : 199\n",
      "BOOKS_AND_REFERENCE : 189\n",
      "DATING : 165\n",
      "VIDEO_PLAYERS : 159\n",
      "MAPS_AND_NAVIGATION : 123\n",
      "FOOD_AND_DRINK : 110\n",
      "EDUCATION : 103\n",
      "ENTERTAINMENT : 85\n",
      "LIBRARIES_AND_DEMO : 83\n",
      "AUTO_AND_VEHICLES : 82\n",
      "HOUSE_AND_HOME : 71\n",
      "WEATHER : 70\n",
      "EVENTS : 63\n",
      "PARENTING : 58\n",
      "ART_AND_DESIGN : 57\n",
      "COMICS : 54\n",
      "BEAUTY : 53\n",
      "None\n",
      "\n",
      "\n",
      "Android table Genre:\n",
      "Tools : 747\n",
      "Entertainment : 538\n",
      "Education : 474\n",
      "Business : 407\n",
      "Productivity : 345\n",
      "Lifestyle : 343\n",
      "Finance : 328\n",
      "Medical : 313\n",
      "Sports : 306\n",
      "Personalization : 294\n",
      "Communication : 286\n",
      "Action : 274\n",
      "Health & Fitness : 273\n",
      "Photography : 261\n",
      "News & Magazines : 248\n",
      "Social : 236\n",
      "Travel & Local : 206\n",
      "Shopping : 199\n",
      "Books & Reference : 189\n",
      "Simulation : 181\n",
      "Dating : 165\n",
      "Arcade : 163\n",
      "Video Players & Editors : 157\n",
      "Casual : 156\n",
      "Maps & Navigation : 123\n",
      "Food & Drink : 110\n",
      "Puzzle : 100\n",
      "Racing : 88\n",
      "Role Playing : 83\n",
      "Libraries & Demo : 83\n",
      "Auto & Vehicles : 82\n",
      "Strategy : 80\n",
      "House & Home : 71\n",
      "Weather : 70\n",
      "Events : 63\n",
      "Adventure : 59\n",
      "Comics : 53\n",
      "Beauty : 53\n",
      "Art & Design : 53\n",
      "Parenting : 44\n",
      "Card : 40\n",
      "Trivia : 37\n",
      "Casino : 37\n",
      "Educational;Education : 35\n",
      "Board : 34\n",
      "Educational : 33\n",
      "Education;Education : 30\n",
      "Word : 23\n",
      "Casual;Pretend Play : 21\n",
      "Music : 18\n",
      "Racing;Action & Adventure : 15\n",
      "Puzzle;Brain Games : 15\n",
      "Entertainment;Music & Video : 15\n",
      "Casual;Brain Games : 12\n",
      "Casual;Action & Adventure : 12\n",
      "Arcade;Action & Adventure : 11\n",
      "Action;Action & Adventure : 9\n",
      "Educational;Pretend Play : 8\n",
      "Simulation;Action & Adventure : 7\n",
      "Parenting;Education : 7\n",
      "Entertainment;Brain Games : 7\n",
      "Board;Brain Games : 7\n",
      "Parenting;Music & Video : 6\n",
      "Educational;Brain Games : 6\n",
      "Casual;Creativity : 6\n",
      "Art & Design;Creativity : 6\n",
      "Education;Pretend Play : 5\n",
      "Role Playing;Pretend Play : 4\n",
      "Education;Creativity : 4\n",
      "Role Playing;Action & Adventure : 3\n",
      "Puzzle;Action & Adventure : 3\n",
      "Entertainment;Creativity : 3\n",
      "Entertainment;Action & Adventure : 3\n",
      "Educational;Creativity : 3\n",
      "Educational;Action & Adventure : 3\n",
      "Education;Music & Video : 3\n",
      "Education;Brain Games : 3\n",
      "Education;Action & Adventure : 3\n",
      "Adventure;Action & Adventure : 3\n",
      "Video Players & Editors;Music & Video : 2\n",
      "Sports;Action & Adventure : 2\n",
      "Simulation;Pretend Play : 2\n",
      "Puzzle;Creativity : 2\n",
      "Music;Music & Video : 2\n",
      "Entertainment;Pretend Play : 2\n",
      "Casual;Education : 2\n",
      "Board;Action & Adventure : 2\n",
      "Video Players & Editors;Creativity : 1\n",
      "Trivia;Education : 1\n",
      "Travel & Local;Action & Adventure : 1\n",
      "Tools;Education : 1\n",
      "Strategy;Education : 1\n",
      "Strategy;Creativity : 1\n",
      "Strategy;Action & Adventure : 1\n",
      "Simulation;Education : 1\n",
      "Role Playing;Brain Games : 1\n",
      "Racing;Pretend Play : 1\n",
      "Puzzle;Education : 1\n",
      "Parenting;Brain Games : 1\n",
      "Music & Audio;Music & Video : 1\n",
      "Lifestyle;Pretend Play : 1\n",
      "Lifestyle;Education : 1\n",
      "Health & Fitness;Education : 1\n",
      "Health & Fitness;Action & Adventure : 1\n",
      "Entertainment;Education : 1\n",
      "Communication;Creativity : 1\n",
      "Comics;Creativity : 1\n",
      "Casual;Music & Video : 1\n",
      "Card;Action & Adventure : 1\n",
      "Books & Reference;Education : 1\n",
      "Art & Design;Pretend Play : 1\n",
      "Art & Design;Action & Adventure : 1\n",
      "Arcade;Pretend Play : 1\n",
      "Adventure;Education : 1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])\n",
    "\n",
    "print('iOS table:')        \n",
    "print(display_table(ios_free, 12))\n",
    "print('\\n')\n",
    "print('Android table Category:')\n",
    "print(display_table(android_free, 1))\n",
    "print('\\n')\n",
    "print('Android table Genre:')\n",
    "print(display_table(android_free, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these tables, we can see some obvious trends. The iOS market is saturated with free games, with relatively few reference, book, and medical apps. The Android market looks similar on the top end (games) but there is significantly more in the way of books and reference apps.\n",
    "\n",
    "Now let's figure out which genres of apps have the most users. We can do this with Installs (index 5) for Android and rating count (index 6) for iOS. Let's start with iOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Productivity : 21028.4\n",
      "Weather : 52279.9\n",
      "Shopping : 27230.7\n",
      "Reference : 79350.5\n",
      "Finance : 32367.0\n",
      "Music : 57326.5\n",
      "Utilities : 19156.5\n",
      "Travel : 28243.8\n",
      "Social Networking : 71548.3\n",
      "Sports : 23008.9\n",
      "Health & Fitness : 23298.0\n",
      "Games : 22886.4\n",
      "Food & Drink : 33333.9\n",
      "News : 21248.0\n",
      "Book : 46384.9\n",
      "Photo & Video : 28441.5\n",
      "Entertainment : 14195.4\n",
      "Business : 7491.1\n",
      "Lifestyle : 16815.5\n",
      "Education : 7004.0\n",
      "Navigation : 86090.3\n",
      "Medical : 612.0\n",
      "Catalogs : 4004.0\n"
     ]
    }
   ],
   "source": [
    "ios_genres = {}\n",
    "ios_genres = freq_table(ios_free, 12)\n",
    "\n",
    "for genre in ios_genres:   #for each genre, set total to zero and length to zero\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    \n",
    "    for app in ios_free:       #then for each app in the dataset...\n",
    "        genre_app = app[12]    \n",
    "        if genre_app == genre:   # see if the genre there matches the genre from our freq table, and if it does...\n",
    "            ratings = app[6]      # define which index number is the ratings count\n",
    "            total += float(ratings)   # add that number to our total\n",
    "            len_genre += 1           #and add 1 to the genre length, ie, total number of genres\n",
    "            \n",
    "    average = total / len_genre       # find average number of ratings by genre\n",
    "    rounded_avg = round(average, 1)\n",
    "    print(genre, ':', rounded_avg)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now Android, which is slightly trickier because we need to get rid of the commas and pluses for the install counts to get flat numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ART_AND_DESIGN : 1986335.1\n",
      "AUTO_AND_VEHICLES : 647317.8\n",
      "BEAUTY : 513151.9\n",
      "BOOKS_AND_REFERENCE : 8814199.8\n",
      "BUSINESS : 1712290.1\n",
      "COMICS : 832613.9\n",
      "COMMUNICATION : 38590581.1\n",
      "DATING : 854028.8\n",
      "EDUCATION : 1833495.1\n",
      "ENTERTAINMENT : 11640705.9\n",
      "EVENTS : 253542.2\n",
      "FINANCE : 1387692.5\n",
      "FOOD_AND_DRINK : 1924897.7\n",
      "HEALTH_AND_FITNESS : 4188822.0\n",
      "HOUSE_AND_HOME : 1360598.0\n",
      "LIBRARIES_AND_DEMO : 638503.7\n",
      "LIFESTYLE : 1446158.2\n",
      "GAME : 15544014.5\n",
      "FAMILY : 3697848.2\n",
      "MEDICAL : 120550.6\n",
      "SOCIAL : 23253652.1\n",
      "SHOPPING : 7036877.3\n",
      "PHOTOGRAPHY : 17840110.4\n",
      "SPORTS : 3650602.3\n",
      "TRAVEL_AND_LOCAL : 13984077.7\n",
      "TOOLS : 10830252.0\n",
      "PERSONALIZATION : 5201482.6\n",
      "PRODUCTIVITY : 16787331.3\n",
      "PARENTING : 542603.6\n",
      "WEATHER : 5145550.3\n",
      "VIDEO_PLAYERS : 24727872.5\n",
      "NEWS_AND_MAGAZINES : 9549178.5\n",
      "MAPS_AND_NAVIGATION : 4049274.6\n"
     ]
    }
   ],
   "source": [
    "android_genres = {}\n",
    "android_genres = freq_table(android_free, 1)\n",
    "\n",
    "for genre in android_genres:   #for each genre, set total to zero and length to zero\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    \n",
    "    for app in android_free:       #then for each app in the dataset...\n",
    "        genre_app = app[1]    \n",
    "        if genre_app == genre:   # see if the genre there matches the genre from our freq table, and if it does...\n",
    "            installs = app[5]      # define which index number is the ratings count\n",
    "            installs = installs.replace(',','') #replace commas with nothing\n",
    "            installs = installs.replace('+','') #replace pluses with nothing\n",
    "            total += float(installs)   # add that number to our total\n",
    "            len_genre += 1           #and add 1 to the genre length, ie, total number of genres\n",
    "            \n",
    "    average = total / len_genre       # find average number of ratings by genre\n",
    "    rounded_avg = round(average, 1)\n",
    "    print(genre, ':', rounded_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, looking at these results and comparing with the counts, some recommendations for apps that tend to have high install numbers but comparatively low market saturation. \n",
    "\n",
    "iOS: Reference, Weather, Utilities\n",
    "Android: Reference\n",
    "\n",
    "However, this is a bit difficult to look at because these tables aren't actually in order. Let's see if we can re-write this to generate a sorted frquency table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1986335.0 : ART_AND_DESIGN\n",
      "647318.0 : AUTO_AND_VEHICLES\n",
      "513152.0 : BEAUTY\n",
      "8814200.0 : BOOKS_AND_REFERENCE\n",
      "1712290.0 : BUSINESS\n",
      "832614.0 : COMICS\n",
      "38590581.0 : COMMUNICATION\n",
      "854029.0 : DATING\n",
      "1833495.0 : EDUCATION\n",
      "11640706.0 : ENTERTAINMENT\n",
      "253542.0 : EVENTS\n",
      "1387692.0 : FINANCE\n",
      "1924898.0 : FOOD_AND_DRINK\n",
      "4188822.0 : HEALTH_AND_FITNESS\n",
      "1360598.0 : HOUSE_AND_HOME\n",
      "638504.0 : LIBRARIES_AND_DEMO\n",
      "1446158.0 : LIFESTYLE\n",
      "15544015.0 : GAME\n",
      "3697848.0 : FAMILY\n",
      "120551.0 : MEDICAL\n",
      "23253652.0 : SOCIAL\n",
      "7036877.0 : SHOPPING\n",
      "17840110.0 : PHOTOGRAPHY\n",
      "3650602.0 : SPORTS\n",
      "13984078.0 : TRAVEL_AND_LOCAL\n",
      "10830252.0 : TOOLS\n",
      "5201483.0 : PERSONALIZATION\n",
      "16787331.0 : PRODUCTIVITY\n",
      "542604.0 : PARENTING\n",
      "5145550.0 : WEATHER\n",
      "24727872.0 : VIDEO_PLAYERS\n",
      "9549178.0 : NEWS_AND_MAGAZINES\n",
      "4049275.0 : MAPS_AND_NAVIGATION\n"
     ]
    }
   ],
   "source": [
    "android_genres = {}\n",
    "android_genres = freq_table(android_free, 1)\n",
    "from operator import itemgetter\n",
    "\n",
    "for genre in android_genres:   #for each genre, set total to zero and length to zero\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    \n",
    "    for app in android_free:       #then for each app in the dataset...\n",
    "        genre_app = app[1]    \n",
    "        if genre_app == genre:   # see if the genre there matches the genre from our freq table, and if it does...\n",
    "            installs = app[5]      # define which index number is the ratings count\n",
    "            installs = installs.replace(',','') #replace commas with nothing\n",
    "            installs = installs.replace('+','') #replace pluses with nothing\n",
    "            total += float(installs)   # add that number to our total\n",
    "            len_genre += 1           #and add 1 to the genre length, ie, total number of genres\n",
    "            \n",
    "    average = total / len_genre       # find average number of ratings by genre\n",
    "    rounded_avg = round(average, 0)\n",
    "    unsorted_table = {}\n",
    "    unsorted_table[genre] = rounded_avg   # putting the values into a new dictionary\n",
    "    table_display = []\n",
    "    for key in unsorted_table:\n",
    "        key_val_as_tuple = (unsorted_table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, key=itemgetter(0), reverse=True)  # HOW CAN WE SORT BY SECOND VALUE IN TUPLE?\n",
    "    for entry in table_sorted:\n",
    "        print(entry[0], ':', entry[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, that didn't work. However, it wasn't strictly necessary, and simply changing the order they're displayed in allows us to easily copy-paste into a spreadsheet and sort that way. That reveals that the top apps on average are news and magazines, books and reference, dating, and comics. Assuming we're looking for non-crowded, high-download apps, **Comics** and **Books and Reference** seem like the best bets, and would probably be easy apps to build to boot (the challenge would be licensing content, probably)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
